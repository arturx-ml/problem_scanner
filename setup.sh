#!/bin/bash

echo "================================================"
echo "Social Media Sentiment Analysis - Setup Script"
echo "================================================"
echo ""

# Check Python version
echo "Checking Python version..."
python3 --version

# Create virtual environment
echo ""
echo "Creating virtual environment..."
python3 -m venv venv

# Activate virtual environment
echo ""
echo "Activating virtual environment..."
source venv/bin/activate

# Upgrade pip
echo ""
echo "Upgrading pip..."
pip install --upgrade pip

# Install requirements
echo ""
echo "Installing dependencies..."
pip install -r requirements.txt

# Download NLTK data
echo ""
echo "Downloading NLTK data..."
python3 << EOF
import nltk
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('vader_lexicon', quiet=True)
    print("âœ“ NLTK data downloaded successfully")
except Exception as e:
    print(f"Note: NLTK download issue: {e}")
EOF

# Create .env file if it doesn't exist
if [ ! -f .env ]; then
    echo ""
    echo "Creating .env file from template..."
    cp .env.example .env
    echo "âœ“ .env file created"
    echo ""
    echo "âš ï¸  IMPORTANT: Edit .env file and add your API credentials!"
fi

echo ""
echo "================================================"
echo "Setup Complete! ðŸŽ‰"
echo "================================================"
echo ""
echo "Next steps:"
echo "1. Edit .env file and add your API credentials:"
echo "   nano .env"
echo ""
echo "2. Activate the virtual environment:"
echo "   source venv/bin/activate"
echo ""
echo "3. Run analysis scripts:"
echo "   python reddit_sentiment_analysis.py"
echo "   python twitter_sentiment_analysis.py"
echo ""
echo "4. Or start Jupyter Notebook:"
echo "   jupyter notebook"
echo ""
echo "================================================"
