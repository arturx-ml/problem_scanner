{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Sentiment Analysis\n",
    "## Analyze sentiment and insights from Reddit posts on a given topic\n",
    "\n",
    "This notebook provides comprehensive sentiment analysis of Reddit posts including:\n",
    "- Data collection from Reddit API\n",
    "- Sentiment analysis using TextBlob and VADER\n",
    "- Visualizations and insights\n",
    "- Export capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set style for visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Reddit API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Reddit API\n",
    "reddit = praw.Reddit(\n",
    "    client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "    client_secret=os.getenv('REDDIT_CLIENT_SECRET'),\n",
    "    user_agent=os.getenv('REDDIT_USER_AGENT', 'SentimentAnalysis/1.0')\n",
    ")\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "print(f\"✓ Connected to Reddit API\")\n",
    "print(f\"✓ Read-only mode: {reddit.read_only}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration - Set Your Analysis Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CONFIGURE YOUR ANALYSIS HERE =====\n",
    "TOPIC = \"artificial intelligence\"  # Change this to your topic of interest\n",
    "SUBREDDIT = \"all\"  # Change to specific subreddit (e.g., 'technology') or keep 'all'\n",
    "LIMIT = 100  # Number of posts to analyze (max depends on Reddit API limits)\n",
    "TIME_FILTER = \"week\"  # Options: 'hour', 'day', 'week', 'month', 'year', 'all'\n",
    "# ========================================\n",
    "\n",
    "print(f\"Analysis Configuration:\")\n",
    "print(f\"  Topic: {TOPIC}\")\n",
    "print(f\"  Subreddit: r/{SUBREDDIT}\")\n",
    "print(f\"  Posts to collect: {LIMIT}\")\n",
    "print(f\"  Time filter: {TIME_FILTER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Collect Reddit Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Collecting {LIMIT} posts about '{TOPIC}' from r/{SUBREDDIT}...\")\n",
    "\n",
    "posts_data = []\n",
    "subreddit_obj = reddit.subreddit(SUBREDDIT)\n",
    "\n",
    "for post in subreddit_obj.search(TOPIC, limit=LIMIT, time_filter=TIME_FILTER):\n",
    "    posts_data.append({\n",
    "        'id': post.id,\n",
    "        'title': post.title,\n",
    "        'text': post.selftext,\n",
    "        'score': post.score,\n",
    "        'upvote_ratio': post.upvote_ratio,\n",
    "        'num_comments': post.num_comments,\n",
    "        'created_utc': datetime.fromtimestamp(post.created_utc),\n",
    "        'subreddit': post.subreddit.display_name,\n",
    "        'author': str(post.author),\n",
    "        'url': post.url,\n",
    "        'permalink': f\"https://reddit.com{post.permalink}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(posts_data)\n",
    "print(f\"✓ Collected {len(df)} posts\")\n",
    "print(f\"\\nDate range: {df['created_utc'].min()} to {df['created_utc'].max()}\")\n",
    "\n",
    "# Display first few posts\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Analyzing sentiment...\")\n",
    "\n",
    "# Combine title and text for analysis\n",
    "df['full_text'] = df['title'] + ' ' + df['text']\n",
    "\n",
    "# TextBlob sentiment\n",
    "df['textblob_polarity'] = df['full_text'].apply(\n",
    "    lambda x: TextBlob(str(x)).sentiment.polarity\n",
    ")\n",
    "df['textblob_subjectivity'] = df['full_text'].apply(\n",
    "    lambda x: TextBlob(str(x)).sentiment.subjectivity\n",
    ")\n",
    "\n",
    "# VADER sentiment\n",
    "vader_scores = df['full_text'].apply(\n",
    "    lambda x: vader.polarity_scores(str(x))\n",
    ")\n",
    "df['vader_compound'] = vader_scores.apply(lambda x: x['compound'])\n",
    "df['vader_pos'] = vader_scores.apply(lambda x: x['pos'])\n",
    "df['vader_neu'] = vader_scores.apply(lambda x: x['neu'])\n",
    "df['vader_neg'] = vader_scores.apply(lambda x: x['neg'])\n",
    "\n",
    "# Classify sentiment\n",
    "df['sentiment_label'] = df['vader_compound'].apply(\n",
    "    lambda x: 'Positive' if x >= 0.05 else ('Negative' if x <= -0.05 else 'Neutral')\n",
    ")\n",
    "\n",
    "print(\"✓ Sentiment analysis complete!\")\n",
    "\n",
    "# Display sample results\n",
    "df[['title', 'vader_compound', 'sentiment_label', 'score']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal posts analyzed: {len(df)}\")\n",
    "print(f\"Average score: {df['score'].mean():.2f}\")\n",
    "print(f\"Average comments: {df['num_comments'].mean():.2f}\")\n",
    "print(f\"Average upvote ratio: {df['upvote_ratio'].mean():.2%}\")\n",
    "\n",
    "print(f\"\\nSentiment Distribution:\")\n",
    "sentiment_dist = df['sentiment_label'].value_counts()\n",
    "for sentiment, count in sentiment_dist.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {sentiment}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAverage VADER Compound Score: {df['vader_compound'].mean():.3f}\")\n",
    "print(f\"Average TextBlob Polarity: {df['textblob_polarity'].mean():.3f}\")\n",
    "\n",
    "print(f\"\\nMost Active Subreddits:\")\n",
    "top_subreddits = df['subreddit'].value_counts().head(5)\n",
    "for subreddit, count in top_subreddits.items():\n",
    "    print(f\"  r/{subreddit}: {count} posts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Sentiment Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Sentiment label distribution (Pie chart)\n",
    "sentiment_counts = df['sentiment_label'].value_counts()\n",
    "axes[0, 0].pie(sentiment_counts.values, labels=sentiment_counts.index, \n",
    "               autopct='%1.1f%%', startangle=90, colors=['#2ecc71', '#95a5a6', '#e74c3c'])\n",
    "axes[0, 0].set_title('Sentiment Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# VADER compound score distribution\n",
    "axes[0, 1].hist(df['vader_compound'], bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "axes[0, 1].axvline(df['vader_compound'].mean(), color='red', \n",
    "                  linestyle='--', label=f\"Mean: {df['vader_compound'].mean():.3f}\")\n",
    "axes[0, 1].set_xlabel('VADER Compound Score')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('VADER Sentiment Score Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Sentiment over time\n",
    "time_sentiment = df.groupby([df['created_utc'].dt.date, 'sentiment_label']).size().unstack(fill_value=0)\n",
    "time_sentiment.plot(kind='area', stacked=True, ax=axes[1, 0], \n",
    "                   color=['#2ecc71', '#95a5a6', '#e74c3c'], alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Number of Posts')\n",
    "axes[1, 0].set_title('Sentiment Trends Over Time', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(title='Sentiment')\n",
    "\n",
    "# Score vs Sentiment\n",
    "sentiment_colors = {'Positive': '#2ecc71', 'Neutral': '#95a5a6', 'Negative': '#e74c3c'}\n",
    "for sentiment in df['sentiment_label'].unique():\n",
    "    data_subset = df[df['sentiment_label'] == sentiment]\n",
    "    axes[1, 1].scatter(data_subset['vader_compound'], data_subset['score'], \n",
    "                     alpha=0.5, label=sentiment, color=sentiment_colors[sentiment])\n",
    "axes[1, 1].set_xlabel('VADER Compound Score')\n",
    "axes[1, 1].set_ylabel('Post Score')\n",
    "axes[1, 1].set_title('Post Score vs Sentiment', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word cloud for all posts\n",
    "text_all = ' '.join(df['full_text'].astype(str))\n",
    "wordcloud_all = WordCloud(width=800, height=400, background_color='white', \n",
    "                         colormap='viridis', max_words=100).generate(text_all)\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.imshow(wordcloud_all, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud - All Posts', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word clouds by sentiment\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sentiments = ['Positive', 'Neutral', 'Negative']\n",
    "colors = ['Greens', 'Greys', 'Reds']\n",
    "\n",
    "for idx, (sentiment, cmap) in enumerate(zip(sentiments, colors)):\n",
    "    data_filtered = df[df['sentiment_label'] == sentiment]\n",
    "    if len(data_filtered) > 0:\n",
    "        text = ' '.join(data_filtered['full_text'].astype(str))\n",
    "        wordcloud = WordCloud(width=600, height=400, background_color='white', \n",
    "                            colormap=cmap, max_words=50).generate(text)\n",
    "        axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'{sentiment} Posts ({len(data_filtered)})', \n",
    "                          fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Engagement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Average score by sentiment\n",
    "sentiment_score = df.groupby('sentiment_label')['score'].mean().sort_values(ascending=False)\n",
    "sentiment_score.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#95a5a6', '#e74c3c'])\n",
    "axes[0].set_title('Average Post Score by Sentiment', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Sentiment')\n",
    "axes[0].set_ylabel('Average Score')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Average comments by sentiment\n",
    "sentiment_comments = df.groupby('sentiment_label')['num_comments'].mean().sort_values(ascending=False)\n",
    "sentiment_comments.plot(kind='bar', ax=axes[1], color=['#2ecc71', '#95a5a6', '#e74c3c'])\n",
    "axes[1].set_title('Average Comments by Sentiment', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Sentiment')\n",
    "axes[1].set_ylabel('Average Comments')\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Top Posts Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 10 POSTS BY SCORE\")\n",
    "print(\"=\"*60)\n",
    "top_posts = df.nlargest(10, 'score')[['title', 'score', 'num_comments', \n",
    "                                       'sentiment_label', 'vader_compound', 'permalink']]\n",
    "display(top_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 10 MOST POSITIVE POSTS\")\n",
    "print(\"=\"*60)\n",
    "most_positive = df.nlargest(10, 'vader_compound')[['title', 'vader_compound', \n",
    "                                                    'score', 'num_comments', 'permalink']]\n",
    "display(most_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOP 10 MOST NEGATIVE POSTS\")\n",
    "print(\"=\"*60)\n",
    "most_negative = df.nsmallest(10, 'vader_compound')[['title', 'vader_compound', \n",
    "                                                     'score', 'num_comments', 'permalink']]\n",
    "display(most_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV\n",
    "output_filename = f'reddit_analysis_{TOPIC.replace(\" \", \"_\")}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"✓ Results exported to '{output_filename}'\")\n",
    "\n",
    "# Export summary statistics\n",
    "summary_filename = f'reddit_summary_{TOPIC.replace(\" \", \"_\")}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.txt'\n",
    "with open(summary_filename, 'w') as f:\n",
    "    f.write(f\"Reddit Sentiment Analysis Summary\\n\")\n",
    "    f.write(f\"Topic: {TOPIC}\\n\")\n",
    "    f.write(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"\\nTotal posts: {len(df)}\\n\")\n",
    "    f.write(f\"Average score: {df['score'].mean():.2f}\\n\")\n",
    "    f.write(f\"Average comments: {df['num_comments'].mean():.2f}\\n\")\n",
    "    f.write(f\"\\nSentiment Distribution:\\n\")\n",
    "    for sentiment, count in df['sentiment_label'].value_counts().items():\n",
    "        f.write(f\"  {sentiment}: {count} ({count/len(df)*100:.1f}%)\\n\")\n",
    "    f.write(f\"\\nAverage VADER Score: {df['vader_compound'].mean():.3f}\\n\")\n",
    "\n",
    "print(f\"✓ Summary exported to '{summary_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook has provided a comprehensive sentiment analysis of Reddit posts on your chosen topic. Key insights include:\n",
    "\n",
    "- Overall sentiment distribution across posts\n",
    "- Temporal trends in sentiment\n",
    "- Engagement metrics by sentiment\n",
    "- Most discussed topics (via word clouds)\n",
    "- Top performing posts\n",
    "\n",
    "You can modify the configuration parameters in Section 3 to analyze different topics, subreddits, or time periods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
